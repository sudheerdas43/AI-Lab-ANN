{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMXv6zqxZgGRPsr+YRleJQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudheerdas43/AI-Lab-ANN/blob/main/ANN_linear_fn_3_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLxajSp_t013",
        "outputId": "358e5b58-44ee-4c02-a54d-352199e4014c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Perceptron for Linear Function\n",
            "Initial weights: [0.60754485 0.17052412 0.06505159], Initial bias: 0.9489\n",
            "Epoch 1: Mean Squared Error: 30.417214\n",
            "Epoch 2: Mean Squared Error: 21.692117\n",
            "Epoch 3: Mean Squared Error: 15.523524\n",
            "Epoch 4: Mean Squared Error: 11.161441\n",
            "Epoch 5: Mean Squared Error: 8.075912\n",
            "Epoch 6: Mean Squared Error: 5.892465\n",
            "Epoch 7: Mean Squared Error: 4.346493\n",
            "Epoch 8: Mean Squared Error: 3.251021\n",
            "Epoch 9: Mean Squared Error: 2.473930\n",
            "Epoch 10: Mean Squared Error: 1.921862\n",
            "Epoch 11: Mean Squared Error: 1.528849\n",
            "Epoch 12: Mean Squared Error: 1.248277\n",
            "Epoch 13: Mean Squared Error: 1.047205\n",
            "Epoch 14: Mean Squared Error: 0.902359\n",
            "Epoch 15: Mean Squared Error: 0.797289\n",
            "Epoch 16: Mean Squared Error: 0.720373\n",
            "Epoch 17: Mean Squared Error: 0.663396\n",
            "Epoch 18: Mean Squared Error: 0.620555\n",
            "Epoch 19: Mean Squared Error: 0.587746\n",
            "Epoch 20: Mean Squared Error: 0.562069\n",
            "Epoch 21: Mean Squared Error: 0.541476\n",
            "Epoch 22: Mean Squared Error: 0.524516\n",
            "Epoch 23: Mean Squared Error: 0.510166\n",
            "Epoch 24: Mean Squared Error: 0.497699\n",
            "Epoch 25: Mean Squared Error: 0.486605\n",
            "Epoch 26: Mean Squared Error: 0.476518\n",
            "Epoch 27: Mean Squared Error: 0.467183\n",
            "Epoch 28: Mean Squared Error: 0.458416\n",
            "Epoch 29: Mean Squared Error: 0.450088\n",
            "Epoch 30: Mean Squared Error: 0.442107\n",
            "Epoch 31: Mean Squared Error: 0.434407\n",
            "Epoch 32: Mean Squared Error: 0.426941\n",
            "Epoch 33: Mean Squared Error: 0.419675\n",
            "Epoch 34: Mean Squared Error: 0.412584\n",
            "Epoch 35: Mean Squared Error: 0.405650\n",
            "Epoch 36: Mean Squared Error: 0.398860\n",
            "Epoch 37: Mean Squared Error: 0.392205\n",
            "Epoch 38: Mean Squared Error: 0.385676\n",
            "Epoch 39: Mean Squared Error: 0.379267\n",
            "Epoch 40: Mean Squared Error: 0.372974\n",
            "Epoch 41: Mean Squared Error: 0.366793\n",
            "Epoch 42: Mean Squared Error: 0.360721\n",
            "Epoch 43: Mean Squared Error: 0.354754\n",
            "Epoch 44: Mean Squared Error: 0.348891\n",
            "Epoch 45: Mean Squared Error: 0.343129\n",
            "Epoch 46: Mean Squared Error: 0.337465\n",
            "Epoch 47: Mean Squared Error: 0.331899\n",
            "Epoch 48: Mean Squared Error: 0.326428\n",
            "Epoch 49: Mean Squared Error: 0.321050\n",
            "Epoch 50: Mean Squared Error: 0.315763\n",
            "Epoch 51: Mean Squared Error: 0.310567\n",
            "Epoch 52: Mean Squared Error: 0.305459\n",
            "Epoch 53: Mean Squared Error: 0.300437\n",
            "Epoch 54: Mean Squared Error: 0.295501\n",
            "Epoch 55: Mean Squared Error: 0.290649\n",
            "Epoch 56: Mean Squared Error: 0.285879\n",
            "Epoch 57: Mean Squared Error: 0.281189\n",
            "Epoch 58: Mean Squared Error: 0.276579\n",
            "Epoch 59: Mean Squared Error: 0.272048\n",
            "Epoch 60: Mean Squared Error: 0.267592\n",
            "Epoch 61: Mean Squared Error: 0.263212\n",
            "Epoch 62: Mean Squared Error: 0.258906\n",
            "Epoch 63: Mean Squared Error: 0.254673\n",
            "Epoch 64: Mean Squared Error: 0.250512\n",
            "Epoch 65: Mean Squared Error: 0.246420\n",
            "Epoch 66: Mean Squared Error: 0.242398\n",
            "Epoch 67: Mean Squared Error: 0.238443\n",
            "Epoch 68: Mean Squared Error: 0.234555\n",
            "Epoch 69: Mean Squared Error: 0.230733\n",
            "Epoch 70: Mean Squared Error: 0.226975\n",
            "Epoch 71: Mean Squared Error: 0.223280\n",
            "Epoch 72: Mean Squared Error: 0.219647\n",
            "Epoch 73: Mean Squared Error: 0.216075\n",
            "Epoch 74: Mean Squared Error: 0.212564\n",
            "Epoch 75: Mean Squared Error: 0.209111\n",
            "Epoch 76: Mean Squared Error: 0.205716\n",
            "Epoch 77: Mean Squared Error: 0.202379\n",
            "Epoch 78: Mean Squared Error: 0.199097\n",
            "Epoch 79: Mean Squared Error: 0.195870\n",
            "Epoch 80: Mean Squared Error: 0.192697\n",
            "Epoch 81: Mean Squared Error: 0.189578\n",
            "Epoch 82: Mean Squared Error: 0.186511\n",
            "Epoch 83: Mean Squared Error: 0.183495\n",
            "Epoch 84: Mean Squared Error: 0.180529\n",
            "Epoch 85: Mean Squared Error: 0.177614\n",
            "Epoch 86: Mean Squared Error: 0.174746\n",
            "Epoch 87: Mean Squared Error: 0.171927\n",
            "Epoch 88: Mean Squared Error: 0.169155\n",
            "Epoch 89: Mean Squared Error: 0.166429\n",
            "Epoch 90: Mean Squared Error: 0.163749\n",
            "Epoch 91: Mean Squared Error: 0.161113\n",
            "Epoch 92: Mean Squared Error: 0.158521\n",
            "Epoch 93: Mean Squared Error: 0.155973\n",
            "Epoch 94: Mean Squared Error: 0.153466\n",
            "Epoch 95: Mean Squared Error: 0.151002\n",
            "Epoch 96: Mean Squared Error: 0.148579\n",
            "Epoch 97: Mean Squared Error: 0.146195\n",
            "Epoch 98: Mean Squared Error: 0.143852\n",
            "Epoch 99: Mean Squared Error: 0.141547\n",
            "Epoch 100: Mean Squared Error: 0.139281\n",
            "Final Weights: [2.09104162 2.63681569 0.23464336], Final Bias: 4.5645\n",
            "Final Mean Squared Error: 0.139281\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.01, n_epochs=100):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_epochs = n_epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def linear_activation(self, x):\n",
        "        return x\n",
        "\n",
        "    def predict(self, X):\n",
        "        weighted_sum = np.dot(X, self.weights) + self.bias\n",
        "        return self.linear_activation(weighted_sum)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.random.rand(n_features)\n",
        "        self.bias = np.random.rand()\n",
        "\n",
        "        print(f\"\\nTraining Perceptron for Linear Function\")\n",
        "        print(f\"Initial weights: {self.weights}, Initial bias: {self.bias:.4f}\")\n",
        "\n",
        "        for epoch in range(self.n_epochs):\n",
        "            predictions = self.predict(X)\n",
        "            errors = y - predictions\n",
        "            mse = np.mean(errors ** 2)\n",
        "\n",
        "            # Update weights and bias\n",
        "            for i in range(n_samples):\n",
        "                error = errors[i]\n",
        "                self.weights += self.learning_rate * error * X[i]\n",
        "                self.bias += self.learning_rate * error\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}: Mean Squared Error: {mse:.6f}\")\n",
        "\n",
        "            # Optional: Stop early if MSE is very low (e.g., < 0.0001)\n",
        "            if mse < 0.0001:\n",
        "                print(f\"Converged after {epoch + 1} epochs\")\n",
        "                break\n",
        "\n",
        "        print(f\"Final Weights: {self.weights}, Final Bias: {self.bias:.4f}\")\n",
        "        print(f\"Final Mean Squared Error: {mse:.6f}\")\n",
        "\n",
        "# Generate dataset\n",
        "np.random.seed(42)  # For reproducibility\n",
        "n_samples = 10\n",
        "X = np.random.uniform(0, 1, (n_samples, 3))\n",
        "y = 2 * X[:, 0] + 3 * X[:, 1] - X[:, 2] + 5\n",
        "\n",
        "# Train Perceptron\n",
        "perceptron = Perceptron(learning_rate=0.01, n_epochs=100)\n",
        "perceptron.train(X, y)"
      ]
    }
  ]
}